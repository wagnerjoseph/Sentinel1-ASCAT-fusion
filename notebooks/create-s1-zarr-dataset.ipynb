{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck as bn\n",
    "import dask\n",
    "import folium\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pystac_client\n",
    "import xarray as xr\n",
    "import yaml\n",
    "import zarr\n",
    "import gc\n",
    "import os\n",
    "import rioxarray\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ascat.read_native.ragged_array_ts import CellFileCollection\n",
    "from collections import defaultdict\n",
    "from dask.distributed import Client\n",
    "from odc import stac as odc_stac\n",
    "import odc.stac\n",
    "from pathlib import Path\n",
    "from pyproj import Transformer\n",
    "from scipy.spatial import cKDTree\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "! pip install geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import io\n",
    "from affine import Affine\n",
    "from rasterio.features import rasterize\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=True,        # Each worker runs in a separate process - saver this way\n",
    "                threads_per_worker=1,  # > 1 leads to multithreading issues\n",
    "                n_workers=50,           # 10GB per worker\n",
    "                memory_limit=\"500GB\"   # we want to stay under 540GB\n",
    "                )\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "\n",
    "collection_id = \"SENTINEL1_SIG0_20M\"\n",
    "\n",
    "collection = eodc_catalog.get_collection(collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of Intesest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area for testing the code (selected area so e.g. the ffill is visible)\n",
    "\"\"\"\n",
    "time_range =\"2022-01-01/2022-03-01\" \n",
    "\n",
    "latmin, latmax = 40, 41         # South to North\n",
    "lonmin, lonmax = -6, -5           # West to East\n",
    "\n",
    "bounding_box = [lonmin, latmin, lonmax, latmax]\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Europe Africa Intersection\n",
    "\"\"\"\n",
    "time_range =\"2022-01-01/2022-02-01\"\n",
    "\n",
    "latmin, latmax = 35, 37            # South to North\n",
    "lonmin, lonmax = -6, -5           # West to East\n",
    "\n",
    "bounding_box = [lonmin, latmin, lonmax, latmax]\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area and Time of Interest\n",
    "# This will not finish on your local pc\n",
    "# Try to run in on a large Cluster\n",
    "#\"\"\"\n",
    "time_range = \"2022-01-01/2023-12-31\"\n",
    "\n",
    "latmin, latmax = 30.0, 45.0            # South to North\n",
    "lonmin, lonmax = -10.0, 5.0            # West to East\n",
    "\n",
    "bounding_box = [lonmin, latmin, lonmax, latmax]\n",
    "\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAC Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = eodc_catalog.search(\n",
    "    collections=collection_id,\n",
    "    bbox=bounding_box,\n",
    "    datetime=time_range,\n",
    "    #max_items=1  # number of max items to load\n",
    ")\n",
    "items_eodc = search.item_collection()\n",
    "print(f\"On EODC we found {len(items_eodc)} items for the given search query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Images to Tiles in Europe and Africa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the Equi7 grid: https://cartography.tuwien.ac.at/eurocarto/wp-content/uploads/2015/09/3_6_ppt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into European and African Equi7 projections\n",
    "\n",
    "items_crs_europe = []\n",
    "items_crs_africa = []\n",
    "\n",
    "for item in items_eodc:\n",
    "    wkt = item.properties[\"proj:wkt2\"]\n",
    "    lat_center = float(wkt.split('PARAMETER[\"latitude_of_center\",')[1].split(']')[0])  # we select based on the latitude of the center of the projection\n",
    "\n",
    "    if lat_center == 53.0:\n",
    "        items_crs_europe.append(item)\n",
    "    elif lat_center == 8.5:\n",
    "        items_crs_africa.append(item)\n",
    "\n",
    "print(f\"Equi7 Europe (lat 53.0): {len(items_crs_europe)} items\")\n",
    "print(f\"Equi7 Africa (lat 8.5): {len(items_crs_africa)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make groups for each tile\n",
    "\n",
    "def extract_tile_id_from_name(item_id):\n",
    "    parts = item_id.split(\"_\")\n",
    "    tile_id = parts[3]\n",
    "    if len(tile_id) == 10:\n",
    "            return tile_id\n",
    "\n",
    "european_tiles = defaultdict(list)\n",
    "african_tiles = defaultdict(list)\n",
    "\n",
    "for item in items_crs_europe:\n",
    "    tile_id = extract_tile_id_from_name(item.id)\n",
    "    if item not in european_tiles[tile_id]:\n",
    "        european_tiles[tile_id].append(item)\n",
    "\n",
    "for item in items_crs_africa:\n",
    "    tile_id = extract_tile_id_from_name(item.id)\n",
    "    if item not in african_tiles[tile_id]:\n",
    "        african_tiles[tile_id].append(item)\n",
    "\n",
    "print(f\"European tiles: {len(european_tiles)}\")\n",
    "print(f\"African tiles: {len(african_tiles)}\")\n",
    "european_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the T3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not want to load all the files we select the ones that are interesting for our analysis\n",
    "\n",
    "<img src=\"..\\images\\Tiles_Europe.jpeg\" alt=\"Tiles of Europe\" width=\"400\">\n",
    "<img src=\"..\\images\\Tiles_Africa.jpeg\" alt=\"Tiles of Europe\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 14 European tiles\n",
    "european_target_tiles = {\n",
    "    \"E027N009T3\", \n",
    "    \"E030N006T3\", \"E030N009T3\", \"E030N012T3\", \"E030N015T3\", \n",
    "    \"E033N006T3\", \"E033N009T3\", \"E033N012T3\", \"E033N015T3\", \n",
    "    \"E036N006T3\", \"E036N009T3\", \"E036N012T3\",\n",
    "    \"E039N009T3\", \"E039N012T3\"\n",
    "}\n",
    "\n",
    "european_tiles = {\n",
    "    tile_id: items\n",
    "    for tile_id, items in european_tiles.items()\n",
    "    if tile_id in european_target_tiles\n",
    "}\n",
    "\n",
    "# Selecting 6 African Tiles\n",
    "african_target_tiles = {\n",
    "    \"E030N090T3\", \"E030N087T3\",\n",
    "    \"E033N090T3\", \"E033N087T3\", \n",
    "    \"E036N090T3\", \"E036N087T3\", \n",
    "}\n",
    "\n",
    "african_tiles = {\n",
    "    tile_id: items\n",
    "    for tile_id, items in african_tiles.items()\n",
    "    if tile_id in african_target_tiles\n",
    "}\n",
    "\n",
    "print(f\"European tiles: {len(european_tiles)}\")\n",
    "print(f\"African tiles: {len(african_tiles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plothing Thumbnail of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing thumbnail image of the data\n",
    "#\"\"\"\n",
    "map = folium.Map(\n",
    "    location=[(latmin + latmax) / 2, (lonmin + lonmax) / 2],\n",
    "    zoom_start=7,\n",
    "    zoom_control=True,\n",
    "    scrollWheelZoom=False,\n",
    "    dragging=False,\n",
    ")\n",
    "\n",
    "folium.Rectangle(\n",
    "    bounds=[[latmin, lonmin], [latmax, lonmax]],\n",
    "    color=\"blue\",\n",
    "    fill=True,\n",
    "    fill_opacity=0.1,\n",
    "    weight=2,\n",
    "    popup=\"Area of Interest\",\n",
    ").add_to(map)\n",
    "\n",
    "for item in european_tiles['E033N012T3']:\n",
    "    # url leading to display of an item, can also be used as hyperlink\n",
    "    image_url = item.assets[\"thumbnail\"].href\n",
    "    bounds = item.bbox\n",
    "    folium.raster_layers.ImageOverlay(\n",
    "        image=image_url,\n",
    "        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n",
    "    ).add_to(map)\n",
    "\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "map\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "\n",
    "resp = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(resp.content)) as z:\n",
    "    folder = \"../data/Shapefiles/ne_110m_admin_0_countries\"\n",
    "    z.extractall(folder)\n",
    "\n",
    "shp_path = os.path.join(folder, \"ne_110m_admin_0_countries.shp\")\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "mask_africa_df = gdf[gdf[\"CONTINENT\"] == \"Africa\"]\n",
    "mask_europe_df = gdf[gdf[\"CONTINENT\"] == \"Europe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check of area of interest\n",
    "area = {\n",
    "    \"minx\": -10.0,\n",
    "    \"maxx\": 5,\n",
    "    \"miny\": 30,\n",
    "    \"maxy\": 45\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "mask_europe_df.plot(ax=ax, edgecolor=\"black\", facecolor=\"lightblue\", linewidth=0.5, label=\"Europe\")\n",
    "mask_africa_df.plot(ax=ax, edgecolor=\"black\", facecolor=\"orange\", linewidth=0.5, label=\"Africa\")\n",
    "ax.set_xlim(area[\"minx\"], area[\"maxx\"])\n",
    "ax.set_ylim(area[\"miny\"], area[\"maxy\"])\n",
    "plt.title(\"Europe and Africa Mask Geometries\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code tile-by-tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tile(tile_id, tiles_dict, crs, output_dir, mask_df, chunk_days=30):\n",
    "\n",
    "    res = 20\n",
    "    chunks = {\"time\": 1, \"y\": 15000, \"x\": 15000} # it gets chunked automatically (selecting a smaller chunk size did not help and lead to issues)\n",
    "    try:\n",
    "\n",
    "        tile_items = tiles_dict[tile_id]\n",
    "\n",
    "        all_times = pd.to_datetime([item.datetime for item in tile_items])\n",
    "        start_time = all_times.min()\n",
    "        end_time = all_times.max()\n",
    "\n",
    "        print(f\"Processing tile {tile_id} from {start_time} to {end_time}\")\n",
    "\n",
    "        current = start_time\n",
    "        while current <= end_time:\n",
    "            next_time = current + timedelta(days=chunk_days)\n",
    "\n",
    "            items_chunk = [\n",
    "                item for item in tile_items \n",
    "                if current <= pd.Timestamp(item.datetime).ceil(\"1h\") < next_time\n",
    "            ]                       # filter items within the current time range\n",
    "\n",
    "            if not items_chunk:\n",
    "                current = next_time\n",
    "                continue\n",
    "\n",
    "            sig0_dc = odc.stac.load(\n",
    "                items_chunk,\n",
    "                crs=crs,\n",
    "                resolution=res,\n",
    "                chunks=chunks,\n",
    "                fail_on_error=False # as on the project pc it had problems with empty items (e.g. SIG0_20220124T063537__VV_D052_E030N006T3)\n",
    "            )                       # loading it localy this somehow works automatically - on Project PC fail_on_error is nesessary\n",
    "\n",
    "            nodata = items_chunk[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"nodata\"]\n",
    "            scale = items_chunk[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"scale\"]\n",
    "\n",
    "            sig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n",
    "            sig0_dc = sig0_dc.rio.clip(mask_df.geometry.values, mask_df.crs)\n",
    "\n",
    "            linear = 10 ** (sig0_dc / 10)\n",
    "            linear.coords[\"time\"] = linear.time.dt.ceil(\"1h\")\n",
    "            hourly = linear.groupby(\"time\").mean(skipna=True)\n",
    "            coarse = hourly.coarsen(x=300, y=300, boundary=\"pad\").mean()\n",
    "            filled = coarse.ffill(dim=\"time\")\n",
    "            back_to_db = 10 * np.log10(filled)\n",
    "\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(output_dir, f\"{tile_id}.zarr\")\n",
    "\n",
    "            if not os.path.exists(output_path):              # write\n",
    "                back_to_db.to_zarr(output_path, mode=\"w\")\n",
    "            else:                                            # or append\n",
    "                back_to_db.to_zarr(output_path, mode=\"a\", append_dim=\"time\")\n",
    "\n",
    "            print(f\"[{tile_id}] Appended {back_to_db.time.size} timesteps from {current.date()} to {next_time.date()}\")\n",
    "\n",
    "            # Clean up memory\n",
    "            del sig0_dc, linear, hourly, coarse, filled, back_to_db\n",
    "            gc.collect()\n",
    "\n",
    "            current = next_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tile {tile_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing European Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile_id, items_list in tqdm(european_tiles.items(), desc=\"Processing European Tiles\"):\n",
    "    with dask.config.set(**{\"array.slicing.split_large_chunks\": False}):\n",
    "        process_tile(\n",
    "            tile_id=tile_id,\n",
    "            tiles_dict=european_tiles,\n",
    "            crs=\"EPSG:27704\",  # Europe CRS\n",
    "            output_dir=\"../data/Sentinel-1/Europe\",\n",
    "            mask_df=mask_europe_df\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing African Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile_id, items_list in tqdm(african_tiles.items(), desc=\"Processing African Tiles\"):\n",
    "    with dask.config.set(**{\"array.slicing.split_large_chunks\": False}):\n",
    "        process_tile(\n",
    "            tile_id=tile_id,\n",
    "            tiles_dict=african_tiles,\n",
    "            crs=\"EPSG:27701\",  # Africa CRS\n",
    "            output_dir=\"../data/Sentinel-1/Africa\",\n",
    "            mask_df= mask_africa_df\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFilling the remaining time chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folders = [\"../data/Sentinel-1/Europe\", \"../data/Sentinel-1/Africa\"]\n",
    "\n",
    "ffill_dim = \"time\"\n",
    "\n",
    "for folder in folders:\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for d in dirs:\n",
    "            if d.endswith(\".zarr\"):\n",
    "                zarr_path = os.path.join(root, d)\n",
    "                \n",
    "                print(f\"Processing {zarr_path}\")\n",
    "                ds = xr.open_zarr(zarr_path)\n",
    "                ds_ffill = ds.ffill(dim=\"time\")\n",
    "                ds_ffill.to_zarr(zarr_path, mode=\"w\")\n",
    "                print(f\"Completed forward fill for {zarr_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    \"../data/Sentinel-1/Europe\", \n",
    "    \"../data/Sentinel-1/Africa\"\n",
    "]\n",
    "\n",
    "summary = []\n",
    "\n",
    "for folder in folders:\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for d in dirs:\n",
    "            if d.endswith(\".zarr\"):\n",
    "                zarr_path = os.path.join(root, d)\n",
    "                \n",
    "                ds = xr.open_zarr(zarr_path)   \n",
    "                    \n",
    "                time_values = pd.to_datetime(ds[\"time\"].values)\n",
    "                n_timesteps = len(time_values)\n",
    "                first_time = time_values[0]\n",
    "                last_time = time_values[-1]\n",
    "                    \n",
    "                month_periods = pd.Series(time_values).dt.to_period(\"M\")\n",
    "                month_counts = month_periods.value_counts()\n",
    "                min_obs_per_month = month_counts.min() if not month_counts.empty else 0\n",
    "                months_covered = month_counts.size\n",
    "                    \n",
    "                summary.append([zarr_path, n_timesteps, first_time, last_time, min_obs_per_month, months_covered])\n",
    "\n",
    "df_summary = pd.DataFrame(summary, columns=[\n",
    "    \"file\", \"timesteps\", \"first_time\", \"last_time\", \"min_obs_per_month\", \"months_covered\"\n",
    "])\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = xr.open_zarr(\"../data/Sentinel-1/Europe/E033N012T3.zarr\")\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the last 30 time values\n",
    "dc_to_plot = dc.isel(time=slice(0, 10))\n",
    "\n",
    "fg = dc_to_plot.VV.plot.imshow(col=\"time\", col_wrap=5, robust=True)\n",
    "[ax.set_aspect('equal') for ax_row in fg.axes for ax in ax_row]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crs = \"EPSG:27704\" # Europe\n",
    "crs = \"EPSG:27701\" # Africa\n",
    "\n",
    "chunks = {\"time\": 1, \"y\": 15000, \"x\": 15000}\n",
    "sig0_dc = odc_stac.load(\n",
    "    #european_tiles['E036N006T3'],\n",
    "    african_tiles['E030N090T3'],\n",
    "    resolution=20, # errror if not set\n",
    "    crs=crs,                                       \n",
    "    chunks=chunks,\n",
    ")\n",
    "\n",
    "nodata = items_eodc[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"nodata\"]\n",
    "scale = items_eodc[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"scale\"]\n",
    "\n",
    "sig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n",
    "\n",
    "#sig0_dc = sig0_dc.rio.clip(mask_africa_df.geometry.values, mask_africa_df.crs)\n",
    "#sig0_dc = sig0_dc.rio.clip(mask_europe_df.geometry.values, mask_europe_df.crs)\n",
    "\n",
    "sig0_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to linear scale to do calculations \n",
    "sig0_dc_linear = 10 ** (sig0_dc / 10)\n",
    "\n",
    "# Merge in time direction \n",
    "sig0_dc_linear.coords['time'] = sig0_dc_linear.time.dt.ceil('1h')\n",
    "sig0_dc_linear_hourly = sig0_dc_linear.groupby('time').mean(skipna=True)\n",
    "\n",
    "# Lower the resolution from 20m to 6km  \n",
    "sig0_dc_linear_6km = sig0_dc_linear_hourly.coarsen(x=300, y=300, boundary='pad').mean() # 15000/300 = 50 pixels in x and y direction (for masked data this is smaller)\n",
    "\n",
    "# ffill values \n",
    "sig_dc_linear_6km_filled = sig0_dc_linear_6km.ffill(dim=\"time\")\n",
    "\n",
    "# Convert back to dB\n",
    "sig_dc_6km = 10 * np.log10(sig_dc_linear_6km_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_dc_6km.to_zarr(\"output_6km_filled.zarr\", mode=\"w\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "sig_dc_6km.isel(time=0).VV.plot.imshow()\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Processing steps for Verification\n",
    "Some plotting to verify if the code produces the intended output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show steps visually:\n",
    "\n",
    "sig0_dc_linear.VV.plot.imshow(col=\"time\", col_wrap=3, robust=True)\n",
    "plt.show()\n",
    "\n",
    "sig0_dc_linear_hourly.VV.plot.imshow(col=\"time\", col_wrap=2, robust=True)\n",
    "plt.show()\n",
    "\n",
    "sig0_dc_linear_6km.VV.plot.imshow(col=\"time\", col_wrap=2, robust=True)\n",
    "plt.show()\n",
    "\n",
    "sig_dc_linear_6km_filled.VV.plot.imshow(col=\"time\", col_wrap=2, robust=True)\n",
    "plt.show()\n",
    "#\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascat-s1-synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
