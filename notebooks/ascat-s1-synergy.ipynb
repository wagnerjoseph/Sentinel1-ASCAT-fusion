{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import folium\n",
    "from odc import stac as odc_stac\n",
    "from ascat.read_native.ragged_array_ts import CellFileCollection\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "import yaml\n",
    "import holoviews as hv\n",
    "import dask\n",
    "\n",
    "dask.config.set(**{\"array.slicing.split_large_chunks\": True})\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "import hvplot.xarray\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    # h121_ds = h121_ds.set_index(time=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = yaml.safe_load(Path(\"../paths.yml\").read_text())\n",
    "root: Path = Path(paths[\"linux\"]).expanduser()\n",
    "cell_source: Path = root / \"datasets/scat_ard/ascat_ssm_cdr_12.5km_h121\"\n",
    "assert cell_source.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Sentinel - 1 Sigma Naught Data from EODC STAC Catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "\n",
    "colllection_id = \"SENTINEL1_SIG0_20M\"\n",
    "\n",
    "collection = eodc_catalog.get_collection(colllection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting time and area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2021-06-01/2021-09-30\"\n",
    "\n",
    "latmin, latmax = 47, 48  # South to North\n",
    "lonmin, lonmax = 15, 16.5  # West to East\n",
    "\n",
    "bounding_box = [lonmin, latmin, lonmax, latmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the metadata with STAC search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = eodc_catalog.search(\n",
    "    collections=colllection_id,\n",
    "    bbox=bounding_box,\n",
    "    datetime=time_range,\n",
    "    # max_items=1  # number of max items to load\n",
    ")\n",
    "items_eodc = search.item_collection()\n",
    "print(f\"On EODC we found {len(items_eodc)} items for the given search query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot thumbnail of the loaded items for this area and those dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(\n",
    "    location=[(latmin + latmax) / 2, (lonmin + lonmax) / 2],\n",
    "    zoom_start=7,\n",
    "    zoom_control=False,\n",
    "    scrollWheelZoom=False,\n",
    "    dragging=False,\n",
    ")\n",
    "\n",
    "folium.Rectangle(\n",
    "    bounds=[[latmin, lonmin], [latmax, lonmax]],\n",
    "    color=\"blue\",\n",
    "    fill=True,\n",
    "    fill_opacity=0.1,\n",
    "    weight=2,\n",
    "    popup=\"Area of Interest\",\n",
    ").add_to(map)\n",
    "\n",
    "for item in items_eodc:\n",
    "    # url leading to display of an item, can also be used as hyperlink\n",
    "    image_url = item.assets[\"thumbnail\"].href\n",
    "    bounds = item.bbox\n",
    "    folium.raster_layers.ImageOverlay(\n",
    "        image=image_url,\n",
    "        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n",
    "    ).add_to(map)\n",
    "\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the data with `odc_stac`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = \"EPSG:27704\"  # Coordinate Reference System: EQUI7 Grid of Europe\n",
    "res = 20  # meter\n",
    "chunks = {\"time\": 1, \"latitude\": 1000, \"longitude\": 1000}\n",
    "sig0_dc = odc_stac.load(\n",
    "    items_eodc,\n",
    "    crs=crs,\n",
    "    resolution=res,\n",
    "    bbox=bounding_box,\n",
    "    chunks=chunks,\n",
    "    resampling=\"bilinear\",\n",
    ")\n",
    "\n",
    "sig0_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items_eodc[-1]\n",
    "scale = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"scale\"]\n",
    "nodata = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"nodata\"]\n",
    "sig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n",
    "\n",
    "sig0_dc = sig0_dc.dropna(dim=\"time\", how=\"all\", subset=[\"VV\"])  # .compute()\n",
    "sig0_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "\n",
    "ds_vv = (\n",
    "    sig0_dc[\"VV\"]\n",
    "    .isel(x=slice(None, None, 10), y=slice(None, None, 10))\n",
    "    .isel(time=slice(0, n))\n",
    ")\n",
    "\n",
    "ncols = 5\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4 * ncols, 4 * nrows))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n):\n",
    "    vv_t = ds_vv.isel(time=i)\n",
    "    ax = axes[i]\n",
    "    im = vv_t.plot(ax=ax, robust=True, cmap=\"viridis\", add_colorbar=False)\n",
    "    ax.set_title(str(vv_t[\"time\"].values)[:19])  # Shorten timestamp\n",
    "    ax.set_xlabel(\"x [m]\")\n",
    "    ax.set_ylabel(\"y [m]\")\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, label=\"VV [dB]\")\n",
    "\n",
    "plt.suptitle(\"Sentinel-1 VV (Downsampled) - First 20 Time Steps\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EODC has items that do not overlap and are about 25 seconds apart, as that is Sentinel-1 radar acquisition time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_t0 = sig0_dc.VV.isel(time=4)\n",
    "vv_t1 = sig0_dc.VV.isel(time=5)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "\n",
    "vv_t0.plot(ax=axes[0], robust=True, cmap=\"viridis\")\n",
    "axes[0].set_title(f\"Sentinel-1 VV - Time 0\\n{str(vv_t0.time.values)}\")\n",
    "\n",
    "vv_t1.plot(ax=axes[1], robust=True, cmap=\"viridis\")\n",
    "axes[1].set_title(f\"Sentinel-1 VV - Time 1\\n{str(vv_t1.time.values)}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to avoid having double the amount of data per time instance, lets merge EODC items per hour. We can also merge per minute, or even day, since for this area we have data every ~4 days, so that is the rough temporal resolution. But let's keep it precision in the hourly range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig0_dc2 = sig0_dc.resample(time=\"d\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_time = sig0_dc.time.dt.floor(\"h\")\n",
    "sig0_dc = sig0_dc.assign_coords(hourly_time=(\"time\", hourly_time.data))\n",
    "sig0_dc = sig0_dc.groupby(\"hourly_time\").mean(dim=\"time\")\n",
    "sig0_dc = sig0_dc.rename({\"hourly_time\": \"time\"})\n",
    "\n",
    "sig0_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "\n",
    "ds_vv = (\n",
    "    sig0_dc[\"VV\"]\n",
    "    .isel(x=slice(None, None, 10), y=slice(None, None, 10))\n",
    "    .isel(time=slice(0, n))\n",
    ")\n",
    "\n",
    "ncols = 5\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4 * ncols, 4 * nrows))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n):\n",
    "    vv_t = ds_vv.isel(time=i)\n",
    "    ax = axes[i]\n",
    "    im = vv_t.plot(ax=ax, robust=True, cmap=\"viridis\", add_colorbar=False)\n",
    "    ax.set_title(str(vv_t[\"time\"].values)[:19])  # Shorten timestamp\n",
    "    ax.set_xlabel(\"x [m]\")\n",
    "    ax.set_ylabel(\"y [m]\")\n",
    "\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, label=\"VV [dB]\")\n",
    "\n",
    "plt.suptitle(\"Sentinel-1 VV (Downsampled) - First 20 Time Steps\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have half of the time instances now. So let's plot first merged item (radar image) to see were images (that were acquired on the same day and in same hour) on the previous plot merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig0_dc.isel(time=0).VV.plot(size=8, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading EUMETSAT H SAF ASCAT H121 data from local TU Wien directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract `gpis` - grid point indices from read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h121_reader = CellFileCollection.from_product_id(cell_source, \"H121_V1.0\")\n",
    "gpis, lons, lats, cells = h121_reader.grid.get_grid_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use specified bounding box that was used to filter out EODC's Sentinel-1 data to filter out grid point indices that are inside this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(\n",
    "    (lats >= latmin) & (lats <= latmax) & (lons >= lonmin) & (lons <= lonmax)\n",
    ")[0]\n",
    "\n",
    "print(\"There are\", len(indices), \"grid point indices inside specified bounding box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an array of those indices that will be used to load individual time series of each point into an `xarray` dataarrays. Those dataarrays will be combined into `xarray` dataset, which will store time series of each individual grid point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_coords = list(zip(lons[indices], lats[indices]))\n",
    "selected_gpis = gpis[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for i, id in enumerate(selected_gpis):\n",
    "    print(f\"Loading location_id: {id} ({i + 1}/{len(selected_gpis)})\")\n",
    "\n",
    "    ds = h121_reader.read(location_id=id)\n",
    "\n",
    "    ds = ds.swap_dims({\"obs\": \"time\"})\n",
    "\n",
    "    ds = ds.expand_dims(location_id=[id])\n",
    "    datasets.append(ds)  # loop takes around 15 seconds\n",
    "\n",
    "ascat_ds = xr.concat(datasets, dim=\"location_id\")  # this will also take a few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascat_ds = ascat_ds.sel(time=slice(*time_range.split(\"/\")))\n",
    "ascat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ascat_ds.time.values[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the results to see how the grid points look like and what is their spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = ascat_ds[\"lat\"].values\n",
    "lons = ascat_ds[\"lon\"].values\n",
    "ids = ascat_ds[\"location_id\"].values\n",
    "\n",
    "center = [lats.mean(), lons.mean()]\n",
    "map = folium.Map(location=center, zoom_start=8)\n",
    "\n",
    "folium.Rectangle(\n",
    "    bounds=[[latmin, lonmin], [latmax, lonmax]],\n",
    "    color=\"blue\",\n",
    "    fill=True,\n",
    "    fill_opacity=0.1,\n",
    "    weight=2,\n",
    "    popup=\"Area of Interest\",\n",
    ").add_to(map)\n",
    "\n",
    "for lat, lon, loc_id in zip(lats, lons, ids):\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=5,\n",
    "        popup=f\"ID: {loc_id}\",\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_color=\"blue\",\n",
    "    ).add_to(map)\n",
    "\n",
    "map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusing Sentinel-1 and ASCAT H SAF datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Regridding Sentinel-1 dataset to the ASCAT grid\n",
    "\n",
    "Let's firstly check the projections of the two datasets, keeping in mind that ASCAT is in WGS84 (EPSG:4326)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig0_crs = sig0_dc.rio.crs\n",
    "print(\"Coordinate reference system of Sentinel-1 dataset:\", sig0_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reprojection has to be done in pairs of latitudes and longitudes, since we are not working with raster, but rather a grid of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up transformer from EPSG:4326 (lat/lon) to EPSG:27704 (Equi7 Grid)\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:27704\", always_xy=True)\n",
    "\n",
    "ascat_lons = ascat_ds[\"lon\"].values\n",
    "ascat_lats = ascat_ds[\"lat\"].values\n",
    "\n",
    "ascat_xs, ascat_ys = transformer.transform(ascat_lons, ascat_lats)\n",
    "\n",
    "# Assign new projected coordinates\n",
    "ascat_reproj_ds = ascat_ds.copy()\n",
    "ascat_reproj_ds = ascat_reproj_ds.assign_coords(\n",
    "    {\"x\": (\"location_id\", ascat_xs), \"y\": (\"location_id\", ascat_ys)}\n",
    ")\n",
    "\n",
    "ascat_reproj_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we have same coordinate reference system for both datasets, let's sample Sentinel-1 to the the grid of ASCAT data- in other words, ASCAT dataset will be master here and its grid will be the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascat_points = ascat_reproj_ds[[\"x\", \"y\"]].to_dataframe().dropna().reset_index()\n",
    "\n",
    "s1_regridded_ds = sig0_dc.sel(\n",
    "    x=xr.DataArray(ascat_points[\"x\"].values, dims=\"location_id\"),\n",
    "    y=xr.DataArray(ascat_points[\"y\"].values, dims=\"location_id\"),\n",
    "    method=\"nearest\",\n",
    ")\n",
    "\n",
    "s1_regridded_ds = s1_regridded_ds.assign_coords(\n",
    "    location_id=(\"location_id\", ascat_points[\"location_id\"].values),\n",
    "    x=(\"location_id\", ascat_points[\"x\"].values),\n",
    "    y=(\"location_id\", ascat_points[\"y\"].values),\n",
    ")\n",
    "\n",
    "s1_regridded_ds = s1_regridded_ds.transpose(\"time\", \"location_id\")\n",
    "\n",
    "s1_regridded_ds = s1_regridded_ds.compute()  # takes a minute\n",
    "s1_regridded_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that simple\n",
    "```\n",
    "sig0_dc.sel(\n",
    "    x=xr.DataArray(ascat_points[\"x\"].values, dims=\"location_id\"),\n",
    "    y=xr.DataArray(ascat_points[\"y\"].values, dims=\"location_id\"),\n",
    "    method=\"nearest\",\n",
    ")\n",
    "```\n",
    "would find a nearest pixel that has data for at a time instance. If closest pixel (let's say 1 meter away) has no value on specific date, but a pixel 400 km away has, it would add it's backscatter value to the time series, which is not so physical. So we would have combined time series of a pixel 1 m away and also 400 000 m away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascat_point = ascat_reproj_ds.isel(location_id=0)\n",
    "target_x = ascat_point[\"x\"].item()\n",
    "target_y = ascat_point[\"y\"].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_x = sig0_dc[\"x\"].values\n",
    "s1_y = sig0_dc[\"y\"].values\n",
    "\n",
    "x_idx = np.abs(s1_x - target_x).argmin()\n",
    "y_idx = np.abs(s1_y - target_y).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_y - target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_series = sig0_dc[\"VV\"].isel(x=x_idx, y=y_idx)\n",
    "vh_series = sig0_dc[\"VH\"].isel(x=x_idx, y=y_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_series.sel(time=slice(\"2021-06-01\", \"2021-06-15\")).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have raster data, but rather gridded vector data, it is the best to plot it as scatter plot, if we are interested in how geospatially gridded Sentinel-1 data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = 0\n",
    "time_sel = s1_regridded_ds[\"time\"].values[time_index]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plotting original Sentinel-1 raster data\n",
    "sig0_dc.isel(time=time_index).VV[::10, ::10].plot(\n",
    "    robust=True, cmap=\"gray\", add_colorbar=False, alpha=0.5\n",
    ")\n",
    "\n",
    "# Plotting gridded Sentinel-1 data\n",
    "scatterplot = plt.scatter(\n",
    "    ascat_reproj_ds[\"x\"].values,\n",
    "    ascat_reproj_ds[\"y\"].values,\n",
    "    c=s1_regridded_ds.VV.sel(time=time_sel).values,\n",
    "    cmap=\"viridis\",\n",
    "    s=50,\n",
    "    edgecolor=\"k\",\n",
    ")\n",
    "\n",
    "plt.colorbar(scatterplot, label=\"Sentinel VV (sampled)\")\n",
    "plt.title(f\"Sentinel VV at ASCAT Grid Points\\nTime: {str(time_sel)}\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_id = 10\n",
    "\n",
    "ascat_sm = ascat_ds.isel(location_id=loc_id).dropna(dim=\"time\").surface_soil_moisture\n",
    "s1_vv = s1_regridded_ds.isel(location_id=loc_id).dropna(dim=\"time\").VV\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# ASCAT on primary y-axis\n",
    "color1 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Time\")\n",
    "ax1.set_ylabel(\"ASCAT Surface Soil Moisture\", color=color1)\n",
    "ax1.plot(ascat_sm.time, ascat_sm, color=color1, label=\"ASCAT SM\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color1)\n",
    "\n",
    "# Sentinel-1 on secondary y-axis\n",
    "ax2 = ax1.twinx()\n",
    "color2 = \"tab:red\"\n",
    "ax2.set_ylabel(\"Sentinel-1 VV\", color=color2)\n",
    "ax2.plot(s1_vv.time, s1_vv, color=color2, label=\"S1 VV\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color2)\n",
    "\n",
    "plt.title(f\"Location ID: {ascat_ds.location_id.values[loc_id]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_regridded_ds.isel(location_id=loc_id).sel(\n",
    "    time=slice(\"2021-06-01\", \"2021-06-15\")\n",
    ").dropna(dim=\"time\").VV.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig0_dc.isel(x=400, y=400).sel(time=slice(\"2021-06-01\", \"2021-06-15\")).dropna(\n",
    "    dim=\"time\"\n",
    ").VV.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Temporal Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can notice that ASCAT data has considerably higher frequency then Sentinel-1. In fact, let's check it programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascat_series = ascat_ds.isel(location_id=loc_id).dropna(\"time\")\n",
    "s1_series = s1_regridded_ds.isel(location_id=loc_id).dropna(\"time\")\n",
    "\n",
    "ascat_counts = ascat_series.resample(time=\"1D\").count()\n",
    "s1_counts = s1_series.resample(time=\"1D\").count()\n",
    "\n",
    "ascat_obs_per_day = ascat_counts.surface_soil_moisture.mean().item()\n",
    "\n",
    "s1_times = s1_series[\"time\"].values\n",
    "s1_time_diffs = (s1_times[1:] - s1_times[:-1]) / np.timedelta64(1, \"D\")\n",
    "s1_avg_interval = np.mean(s1_time_diffs)\n",
    "\n",
    "print(f\"ASCAT avg observations per day: {ascat_obs_per_day:.2f}\")\n",
    "print(f\"Sentinel-1 avg revisit time: {s1_avg_interval:.2f} days\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ascat_counts.surface_soil_moisture.plot(label=\"ASCAT\", linewidth=1)\n",
    "s1_counts.VV.plot(label=\"Sentinel-1\", linewidth=2)\n",
    "plt.title(f\"Temporal Sampling per Day at Location Index: {loc_id}\")\n",
    "plt.ylabel(\"Observations per Day\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascat_times = ascat_ds[\"time\"]\n",
    "s1_expanded = s1_regridded_ds.sel(time=ascat_times, method=\"nearest\")\n",
    "\n",
    "s1_expanded[\"time\"] = ascat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_expanded.VV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascat-s1-synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
